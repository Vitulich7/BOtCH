{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnUSF3OAyrWe"
      },
      "outputs": [],
      "source": [
        "# BOtCH: улучшенный чат-бот с генеративной моделью DialoGPT\n",
        "В этом ноутбуке реализован бот с DialoGPT, базовая оценка качества и демонстрация.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch nltk matplotlib --quiet\n"
      ],
      "metadata": {
        "id": "4ABwh-ncywhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "8qApwPzEyy_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'microsoft/DialoGPT-small'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "Hrlutygby1Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(history, user_input, max_length=1000):\n",
        "    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
        "    bot_input_ids = torch.cat([history, new_user_input_ids], dim=-1) if history is not None else new_user_input_ids\n",
        "    output_ids = model.generate(bot_input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
        "    response_ids = output_ids[:, bot_input_ids.shape[-1]:]\n",
        "    response_text = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n",
        "    return output_ids, response_text\n"
      ],
      "metadata": {
        "id": "yyvfQ3M2y2u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = None\n",
        "user_inputs = [\n",
        "    \"Привет!\",\n",
        "    \"Как тебя зовут?\",\n",
        "    \"Расскажи шутку\",\n",
        "    \"Спасибо, пока!\"\n",
        "]\n",
        "\n",
        "for user_input in user_inputs:\n",
        "    history, bot_response = generate_response(history, user_input)\n",
        "    print(f\"Пользователь: {user_input}\")\n",
        "    print(f\"БОТ: {bot_response}\")\n",
        "    print('---')\n"
      ],
      "metadata": {
        "id": "xn3xhCjly4uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "test_data = [\n",
        "    (\"Привет!\", \"Привет! Как я могу помочь?\"),\n",
        "    (\"Как тебя зовут?\", \"Я бот, меня зовут BOtCH.\"),\n",
        "    (\"Расскажи шутку\", \"Почему программисты любят природу? Потому что там много багов!\"),\n",
        "    (\"Пока\", \"До свидания!\")\n",
        "]\n",
        "\n",
        "bleu_scores = []\n",
        "for question, reference in test_data:\n",
        "    _, response = generate_response(None, question)\n",
        "    reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "    response_tokens = nltk.word_tokenize(response.lower())\n",
        "    score = sentence_bleu([reference_tokens], response_tokens)\n",
        "    bleu_scores.append(score)\n",
        "    print(f\"Вопрос: {question}\")\n",
        "    print(f\"Ответ бота: {response}\")\n",
        "    print(f\"Эталон: {reference}\")\n",
        "    print(f\"BLEU: {score:.3f}\")\n",
        "    print('---')\n"
      ],
      "metadata": {
        "id": "gsvUDUpey6zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(range(len(bleu_scores)), bleu_scores, tick_label=[q for q, _ in test_data])\n",
        "plt.title('BLEU scores for test questions')\n",
        "plt.ylabel('BLEU score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jU-0Zep7y83V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}